{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QBio Python Workshop Week 5\n",
    "\n",
    "## Pandas and Seaborn, Pt 1\n",
    "\n",
    "Prepared and presented by Gloria Ha (gloriaha@g.harvard.edu) with reference to notes by Mary Richardson for MCB112.\n",
    "\n",
    "### Outline\n",
    "- Basic Pandas\n",
    "    - Importing data\n",
    "    - Cleaning dataframe\n",
    "    - Referencing columns\n",
    "    - Creating new columns\n",
    "    - Sorting dataframe\n",
    "- Basic Seaborn\n",
    "    - Plotting data from a dataframe\n",
    "- More Pandas\n",
    "    - Grouping data\n",
    "    - Creating a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data\n",
    "\n",
    "**Pandas**, or Python Data Analysis Library, is a package that makes it easy to import, view, clean up, and analyze data.  We will focus on a Pandas data structure called a **DataFrame**, which is a 2D table with labeled rows and columns.\n",
    "\n",
    "For today's lesson, we'll be using toy data from my own research.  I'm interested in quantifying chromosome segregation errors in cell division through live-cell imaging.  In normal cell division, one cell aligns the chromosomes at the center of the cell and divides an equal number of chromatids (1 from each chromosome) into two daughter cells.  In my experiments, I force cells to undergo anaphase (chromatid separation) at different times using a drug.  I then observe (1) when the cells go into anaphase and (2) how many chromatids are in each daughter cell after division.  \n",
    "\n",
    "\n",
    "Let's go ahead and take a look at the data, which I've provided in a comma-separated values (.csv) format.  We can preview a file using the command line argument `!head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head kt_counts.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data.  Since it's in a CSV (comma-separated values) format, we can use `pd.read_csv`\n",
    "\n",
    "Since the CSV file already has the headers we need, we don't need to specify the column names.  I'll provide the code to import the data with specified column names in the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "imported_df = pd.read_csv('kt_counts.csv')\n",
    "\n",
    "# import data with specified column names (have to get rid of the first row since it's redundant now)\n",
    "# imported_df = pd.read_csv('kt_counts.csv',names=['sample','forced_time','position','N1','N2','anaphase_time','congression'],skiprows=1)\n",
    "\n",
    "# take a look at the dataframe (default is the first five rows)\n",
    "imported_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the same information as the preview from the command line, but looks a lot nicer and spaced out.  \n",
    "\n",
    "There are 7 columns here.\n",
    "- **sample**: ID number of sample\n",
    "- **forced_time**: time of drug addition (minutes)\n",
    "- **position**: ID number of cell within the sample\n",
    "- **N1**: number of chromatids in cell 1\n",
    "- **N2**: number of chromatids in cell 2\n",
    "- **anaphase_time**: time of chromatid separation (minutes)\n",
    "- **congression**: whether or not the chromosomes aligned at the center of the cell before anaphase (Y/N)\n",
    "\n",
    "This data is **tidy**\n",
    "\n",
    "What that means is (https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html):\n",
    "- Every column is a variable.\n",
    "\n",
    "- Every row is an observation.\n",
    "\n",
    "- Every cell is a single value.\n",
    "\n",
    "Today we're starting with a tidy dataframe.  Mary will go more into the process of tidying data next week!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning dataframe\n",
    "\n",
    "Next we need to clean the data.  There are some cells that I wasn't able to analyze, so there is either no data or text in the `N1` and `N2` columns.  There are also some where I couldn't get the anaphase times.  Let's use the Pandas function `isna()` to check for empty cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store information on empty status of each entry in the dataframe\n",
    "isna = imported_df.isna()\n",
    "isna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like most of our data is fine.  If we want to isolate and display the rows that have empty cells, we can first check which rows have any empty cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for rows with any empty cells\n",
    "empty_rows = imported_df.isna().any(axis=1)\n",
    "empty_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's display those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display empty rows\n",
    "imported_df[empty_rows]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two cells with missing data, so now we can get rid of them using the `dropna()` function.  We can either specify which columns to search for empty cells in, or get rid of all rows with any empty cells at all.  I'll show you both ways below.  We'll store the new, clean dataframe in a new dataframe called `cleaned_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commented out: how to specify which columns to search for empty cells in\n",
    "# cleaned_df = imported_df.dropna(subset=['N1','N2','anaphase_time'])\n",
    "\n",
    "# drop rows with any empty cells!\n",
    "cleaned_df = imported_df.dropna()\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure that we got rid of the rows with empty cells, we can check how many rows the dataframe has now.  There should be 87 rows now since there were 89 before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  You'll notice that even though there are 87 rows, the indices on the left of the dataframe still go to 88.  We can reset the index of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.reset_index(drop=True) \n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that I keep re-defining `cleaned_df`.  Another way to accomplish the same thing is to make the operations `inplace=True`.  For example, another way of doing the above command is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.reset_index(drop=True, inplace=True) \n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencing columns\n",
    "\n",
    "You can reference columns of dataframes using brackets.  For example, if I wanted to print out the drug addition times for each cell, I could write `cleaned_df['forced_time']`.  In Pandas, column names are strings.  Let's check out the anaphase times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df['anaphase_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate things from our dataframe.  **Try calculating the mean `anaphase_time` for all of the cells.**  There are multiple ways to do this, including with numpy (`np.mean()`).  You can also take the series and directly call the function `mean()`: `df['column name'].mean()`.  Similarly, you can use `sum()`, `max()`, `mean()`, and many other functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean anaphase time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to calculate the mean anaphase time just for cells that were forced into anaphase at 20 minutes?  We can call a subset of a dataframe that satisfies some condition like this:\n",
    "\n",
    "`df[df['column_name']==VAL]`\n",
    "\n",
    "**Try showing the subset of the dataframe for cells that were forced into anaphase at 20 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the part of the dataframe with cells forced into anaphase at 20 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try **calculating the mean anaphase time for cells that were forced into anaphase at 20 minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean anaphase time for cells forced into anaphase at 20 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new columns\n",
    "\n",
    "You can also create new columns in a dataframe.  For example, if I wanted to have a new column called 'force_to_anaphase' specifying how long after the drug addition time the cell went into anaphase, I would do:\n",
    "\n",
    "`cleaned_df['force_to_anaphase'] = cleaned_df['anaphase_time']-cleaned_df['forced_time']`.\n",
    "\n",
    "What we're actually interested in looking at today is the difference in the number of chromatids between each pair of daughter cells ($\\Delta N = |N_1-N_2|$).  We can define a new column `dN` with this metric.  Try defining a new column in our dataframe and then taking a look at the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new column dN =|N1-N2|\n",
    "\n",
    "# take a look at the resulting dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of our important numerical data is already in float format, but there are times when the data is not, so we need to convert everything to floats (or whatever data type you desire). Here's how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dN and anaphase time data to floats\n",
    "cleaned_df.astype({'dN': 'float','anaphase_time':'float'})\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting dataframe\n",
    "\n",
    "There are various reasons why you might want to sort your dataframe.  It might be for visualization purposes or to make downstream calculations easier.  Let's try sorting the dataframe by drug addition time.\n",
    "\n",
    "The general command for sorting a dataframe is\n",
    "`df = df.sort_values(by=['column_name'])`\n",
    "\n",
    "You can also sort in descending order by specifying `ascending=False`. You can sort by column A and then sort any ties by column B by passing `['column_A','column_B']`.\n",
    "\n",
    "Try sorting the dataframe by `'forced_time'` in ascending order and taking a look at the resulting dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort dataframe by forced_time column\n",
    "\n",
    "# take a look at the resulting dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the indices are all shuffled again.  Though it doesn't matter for our purposes today, you can reindex the dataframe again using the same command as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.reset_index(drop=True, inplace=True) \n",
    "cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data from a dataframe\n",
    "\n",
    "Now that we have our nice and clean dataframe we can start looking at the data!  You can always use standard Matplotlib functionality to plot data from Pandas dataframes.  Let's plot a histogram of the $\\Delta N$ values for cells that were forced into anaphase at 10 minutes using the standard `plt.hist()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of dN values for cells forced into anaphase at 10 minutes\n",
    "plt.hist(cleaned_df[cleaned_df['forced_time']==10]['dN']);\n",
    "plt.xlabel('dN');\n",
    "plt.ylabel('number of cells');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nice thing about **Seaborn** is that we can plot directly from the dataframe and display things according to our desired attributes.  For most Seaborn plotting functions, the arguments include:\n",
    "- **data**: dataframe or subset of dataframe to plot\n",
    "- **x**: column to plot data from (string)\n",
    "- **hue**: column to color data based on (string)\n",
    "- **y**: column to plot data from (string, for 2D plots)\n",
    "\n",
    "**Try using `sns.histplot()` with the `data`, `x`, and `hue` arguments for plotting `dN` for the cells forced into anaphase at 10 minutes, colored by chromosome congression.**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a histogram of dN values for cells forced into anaphase at 10 minutes using sns.histplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, Seaborn automatically adds in x and y axis labels for your plot and provides a nice legend for your coloring.\n",
    "\n",
    "What's a good way to look at all of the data at once?  We could try plotting all of the dNk data as a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=cleaned_df, x='dN',hue='forced_time');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not very nice.  It would be better to separate out the data.  One option is `sns.swarmplot()`.  **Try plotting `forced_time` on the x-axis and `dN` on the y-axis, and coloring by chromosome congression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot dN vs forced_time using sns.swarmplot()\n",
    "plt.figure(figsize=(15,8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try doing the same thing but for anaphase onset times (you should only have to change one argument).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data\n",
    "\n",
    "So far we've tried displaying all of the data, and there seems to be a time dependent trend!  To quantify that trend, I want to condense the data into some statistical measurements.  I'm interested in the mean and standard error of the mean for each timepoint for $\\Delta N$.  There's a handy Pandas function `groupby()` where you can group the dataframe by some parameter.  In my case, I want to group rows by `forced_time`.  Let's see what happens if I display the means of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.groupby('forced_time').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these columns don't make much sense (average position or sample number mean nothing to me!), but the average anaphase time and $\\Delta N$ are things I am interested in!\n",
    "\n",
    "I can take a look at just the mean `dN` values by group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df.groupby('forced_time').mean()['dN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can use `.sem()` similarly to calculate the standard error of the mean of `dN` for each group, and `.count()` to calculate how many cells are in each group.\n",
    "\n",
    "**Try making three new variables: `counts`,`means`,and `sems` that contain the information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store statistical measurements in new variables\n",
    "counts = \n",
    "means = cleaned_df.groupby('forced_time').mean()['dN']\n",
    "sems = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new dataframe\n",
    "\n",
    "Let's get some practice making a new dataframe.  This is the dataframe I want:\n",
    "\n",
    "| forced_time | count | mean | sem |\n",
    "| --- | --- | --- | --- |\n",
    "| 10 |  |  |  |\n",
    "| 20 |  |  |  |\n",
    "| 30 |  |  |  |\n",
    "\n",
    "Where count is the number of cells in each group, and mean and sem are measurements of `dN`.\n",
    "\n",
    "First, let's make a dictionary containing this information.  You can plug in the variables you just made (`counts`,`means`,and `sems`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_dict = {'count': counts,\n",
    "             'mean': means,\n",
    "             'sem': sems}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a dataframe from this is super easy now!  The dictionary keys become the columns and the values become the cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataframe for statistics\n",
    "stat_df = pd.DataFrame(stat_dict)\n",
    "\n",
    "# reindex dataframe\n",
    "stat_df = stat_df.reset_index()\n",
    "stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot how the mean `dN` changes over time and plot error bars as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(stat_df['forced_time'],stat_df['mean'],yerr=stat_df['sem'],fmt='o-')\n",
    "plt.xlabel('forced_time (min)')\n",
    "plt.ylabel('<dN>');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
