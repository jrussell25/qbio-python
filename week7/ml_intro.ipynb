{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e2f3ce-a6fb-4cad-a5d2-8c0379f27178",
   "metadata": {},
   "source": [
    "# A lightning introduction to machine learning (ML)\n",
    "\n",
    "Prepared by Jacob Zavatone-Veth (<jzavatoneveth@g.harvard.edu>).\n",
    "\n",
    "This week, we'll wrap up the bootcamp series by giving you a lightning introduction to machine learning (ML). This notebook will introduce some basic ML concepts and vocabulary; you'll get to apply this knowledge in the next notebook. \n",
    "\n",
    "This is not a comprehensive introduction to machine learning. For more Python examples, see the Jupyter notebook version of the [Python Data Science Handbook](https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/Index.ipynb). For more detailed information, the following books are useful references:\n",
    "- [Bishop, *Pattern Recognition and Machine Learning*](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf)\n",
    "- [Goodfellow, Bengio, and Courville, *Deep Learning*](https://www.deeplearningbook.org)\n",
    "- [Hertz, Krogh, and Palmer, *Introduction to the Theory of Neural Computation*](https://www.amazon.com/Introduction-Theory-Neural-Computation-Institute/dp/0201515601)\n",
    "\n",
    "In Python, the main packages currently used (to my knowledge) for ML functionality beyond Numpy and SciPy are [scikit-learn](https://scikit-learn.org), [PyTorch](https://pytorch.org) and [TensorFlow](https://www.tensorflow.org). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50c0dc-5101-4bf8-b8bb-af1735623a5c",
   "metadata": {},
   "source": [
    "## What is ML?\n",
    "The basic goal of ML is to find patterns in data. To seach for these patterns, ML constructs a mathematical model for the structure of data; the ''learning'' in ''machine learning'' refers to having a computer adapt some ''free parameters'' of the model to ''fit'' observed data. The boundaries of ML are [somewhat fuzzy](https://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/ckelmtt/?context=3), but these general principles are shared. ML is traditionally divided into *supervised learning*, *unsupervised learning*, and *reinforcement learning*. These three categories are differentiated by the nature of the feedback used to adapt model parameters; we discuss them below in turn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8deb8b-9b64-4664-a08c-019cc337e95d",
   "metadata": {},
   "source": [
    "## Supervised learning\n",
    "In a supervised learning task, the goal is to learn a function that maps inputs $x$ to outputs $y$ given a set of example input-output pairs $\\{(x_{\\mu},y_{\\mu})\\}_{\\mu=1}^{p}$. To do so, one must select some family of functions to model the data, as well as some cost that measures how well a given function models the observed data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73aaeb-d189-46bf-998f-a67bada32d67",
   "metadata": {},
   "source": [
    "Probably the simplest form of supervised learning is linear regression, which we discussed [back in Week 4](https://github.com/jrussell25/qbio-python/blob/summer21/week4/week4_regression.ipynb). There, the model for the input-output map $x \\mapsto y$ is simply $y = \\beta^{\\top} x + \\epsilon$ for some matrix $\\beta$ and residuals $\\epsilon$. Most commonly, one seeks parameters $\\beta$ that minimize the least-squares cost $L(\\beta)=\\sum_{\\mu=1}^{p}\\Vert \\beta^{\\top} x_{\\mu}-y_{\\mu} \\Vert_{2}^{2}$ (see the [Week 4 notebook](https://github.com/jrussell25/qbio-python/blob/summer21/week4/week4_regression.ipynb) for more details). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593d2ac1-da37-44f0-89b8-15b0ade3bd45",
   "metadata": {},
   "source": [
    "Most supervised learning tasks will be of the same form: one chooses a parametric family of functions $f_{\\theta}$ (most famously [deep neural networks](https://en.wikipedia.org/wiki/Artificial_neural_network)), and chooses the parameters $\\theta$ by minimizing some cost $L(\\theta)$ that measures the error on the training set for a given choice of parameters. Regardless of the setting, the eventual goal is to use the trained model $f_{\\theta_{\\ast}}$ to predict the output for an unseen input, i.e., to obtain a model that *generalizes* beyond the training set.\n",
    "\n",
    "Probably the best-known supervised learning task is [image recognition](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf). For an introduction to these methods, see the [PyTorch](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html) or [TensorFlow](https://www.tensorflow.org/tutorials/images/classification) tutorials. \n",
    "\n",
    "Later in this session, you'll have the chance to experiment with a more complex supervised learning model and real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e28e7d-a4e8-4a77-8538-91117b41350e",
   "metadata": {},
   "source": [
    "## Unsupervised learning\n",
    "In unsupervised learning tasks, the learner must find structure in its input without externally-provided labels. The canonical example of an unsupervised learning algorithm is PCA, which we discussed in Week 4. For a PCA demo and an introduction to other dimensionality reduction algorithms, see the [Week 4 notebook](https://github.com/jrussell25/qbio-python/blob/summer21/week4/week4_dimred.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b34b15-319c-4e40-9b3d-e7c123bf3c24",
   "metadata": {},
   "source": [
    "## Reinforcement learning\n",
    "Reinforcement learning (RL) is rather different from supervised and unsupervised learning; it considers how an agent should choose its actions as it navigates an environment in order to maximize some notion of reward. In recent years, RL has gained prominence through [DeepMind's](https://deepmind.com/) work on the games of [Go](https://deepmind.com/research/case-studies/alphago-the-story-so-far), [chess](https://deepmind.com/blog/article/alphazero-shedding-new-light-grand-games-chess-shogi-and-go), and [Starcraft](https://deepmind.com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09458cf0-c934-4396-8c5a-324033f6ea3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
