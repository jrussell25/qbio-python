{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas for Pros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "Today we're going to look at translation data for the SARS-CoV-2 virus from [Finkel et al. Nature (2020)](https://www.nature.com/articles/s41586-020-2739-1). We have access to plenty of data about SARS-CoV-2 that will help us explore this data. We'll just focus on two publically available files:\n",
    "- the annotations (downloaded from [NCBI RefSeq](https://www.ncbi.nlm.nih.gov/sars-cov-2/))\n",
    "- the ribosome profiling density reported in the study (downloaded from [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE149973))\n",
    "\n",
    "Let's take a look at our downloaded input data files so we know how to load them. Preview the files using the command line argument `!head`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out GTF file format: https://useast.ensembl.org/info/website/upload/gff.html\n",
    "!head sarscov2_annotations.gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out wig file format: https://m.ensembl.org/info/website/upload/wig.html\n",
    "!head 24hr_riboseq.wig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input file names\n",
    "annotations_file = 'sarscov2_annotations.gtf'\n",
    "riboseq_05hr_file = '05hr_riboseq.wig'\n",
    "riboseq_07hr_file = '07hr_riboseq.wig'\n",
    "riboseq_24hr_file = '24hr_riboseq.wig'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe\n",
    "\n",
    "We can read in data with:\n",
    "- `pd.read_csv(filename)` for a comma separated file \n",
    "- `pd.read_table(filename)` for a tab separated file\n",
    "- `pd.read_table(filename, sep='')` for any separator we choose \n",
    "\n",
    "Check out the [documentation](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_table.html) to decide which additional arguments we need to read in both files. Useful optional arguments include:\n",
    "- `comment=None` (default) or `comment='#'`\n",
    "- `header=1` (default) or `header=None`\n",
    "- `skiprows=None` (default) or `skiprows=1`\n",
    "- `names=['col1', 'col2']`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the annotations\n",
    "\n",
    "# Set the column names\n",
    "feature_names = ['chromosome','source','feature','start','end','score','strand','frame','attributes']\n",
    "\n",
    "# Read the table into a dataframe\n",
    "annotations =\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the dataframe index\n",
    "\n",
    "Another useful trick is setting and resetting the index (or the row names).\n",
    "\n",
    "To set the index:\n",
    "- `df.set_index('col', inplace=True)` to set an existing column as the index\n",
    "- `df.reindex([value1, value2])` to set a new list of values as the index (the list of values must be the same length as the dataframe)\n",
    "\n",
    "To remove the index:\n",
    "- `df.reset_index(inplace=True)` to move the index column back into the dataframe\n",
    "- `df.reset_index(drop=True, inplace=True)` to remove the index column completely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the ribo-seq data\n",
    "\n",
    "# Set the column names\n",
    "feature_names = ['position','reads']\n",
    "\n",
    "# Read the table into a dataframe\n",
    "riboseq_05hr = \n",
    "riboseq_07hr = \n",
    "riboseq_24hr = \n",
    "\n",
    "# Set the index to be the positions column\n",
    "\n",
    "\n",
    "riboseq_24hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove extra info\n",
    "\n",
    "It's useful to clean up our data before we do any analysis or plotting. This includes:\n",
    "- splitting up any columns that contain multiple values or mixed data types\n",
    "- removing rows we don't need\n",
    "- removing columns we don't need\n",
    "\n",
    "To clean up columns with multiple values:\n",
    "- `df['col'].str` to access the column value as a string\n",
    "- `str.extract(r'regex')` to search for values that match a pattern in the string\n",
    "- `str.split()` to split the string on whitespace (default) or any other separator\n",
    "- `str[0]` to access a specific element of a split string\n",
    "- `str[0:5]` to get a substring of the string\n",
    "\n",
    "To remove rows:\n",
    "- `df.drop(rows=['row1','row2'], inplace=True)` to drop rows by index name (useful if you set named indices)\n",
    "- `df[df['col']==value]` to create a view of the dataframe with the desired rows filtered by value\n",
    "- `df.copy()` to create a copy of the filtered dataframe we can actually use\n",
    "\n",
    "To remove columns:\n",
    "- `df.drop(columns=['col1','col2'], inplace=True)` to drop columns by column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the annotations dataframe\n",
    "\n",
    "# Replace the attributes column with a transcript_id column and a gene name column\n",
    "annotations['transcript_id'] = \n",
    "annotations['gene'] = \n",
    "\n",
    "# Remove rows we don't need (keep only transcript features)\n",
    "\n",
    "\n",
    "# Remove columns we don't need (chromosome, source, score, strand, frame, attributes, feature, transcript_id)\n",
    "\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add missing info\n",
    "\n",
    "Sometimes we might also need to add in missing data by:\n",
    "- filling NaN values with meaningful values\n",
    "- adding new rows\n",
    "- adding new columns\n",
    "\n",
    "To fill NaN values:\n",
    "- `df.fillna(value)` to fill the whole dataframe's missing values\n",
    "- `df['col'].fillna(value)` to fill a specific column's missing values\n",
    "\n",
    "To add new rows:\n",
    "- `df.append(df2), ignore_index=True` to append a dataframe with new rows\n",
    "- `df.reindex([value1, value2])` to add rows for all index values specified\n",
    "- `df.reindex([value1, value2], fill_value=0)` to add rows for all index values specified and fill missing values\n",
    "\n",
    "To add new columns:\n",
    "- `df['col'] = value` to add a column with a single value for all rows\n",
    "- `df['col'] = [value1, value2]` to add a column with the specified values (the list of values must be the same length as the dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the riboseq dataframe\n",
    "\n",
    "# Add the missing positions to each dataframe, from one to the max genome position\n",
    "pos_max = # Find the max value in the end column\n",
    "new_index = # Create a range from 1 to max\n",
    "\n",
    "# Reindex the dataframe with this new index\n",
    "riboseq_05hr = \n",
    "riboseq_07hr = \n",
    "riboseq_24hr = \n",
    "\n",
    "# Add a column with the timepoint in hrs (5, 7, or 24)\n",
    "riboseq_05hr['timepoint'] = \n",
    "riboseq_07hr['timepoint'] = \n",
    "riboseq_24hr['timepoint'] = \n",
    "\n",
    "riboseq_24hr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply a function to the dataframe\n",
    "\n",
    "Often we want to run a function on one or more columns or rows of a dataframe.\n",
    "\n",
    "To apply a custom or existing function a dataframe:\n",
    "- `df.apply(fxn, axis=0)` to apply the function to each column\n",
    "- `df.apply(fxn, axis=1)` to apply the function to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with the full range of transcript coordinates for each transcript\n",
    "\n",
    "# Write a function to return the range of values from start to end+1 for a given row\n",
    "def feature_range(row):\n",
    "    return \n",
    "\n",
    "# Add a position column with the list of all positions from start to end for each row\n",
    "annotations['position'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explode the dataframe\n",
    "\n",
    "In the case of biological data, it can occasionally be helpful to add one row for each position of a sequence. In this case, we want to add one row per transceript position.\n",
    "\n",
    "Explode a dataframe to have one row for each value in a list:\n",
    "- `df.explode('col')` to add one row per value in the column list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat the annotations dataframe to include one row per transcript position\n",
    "# so that we can merge it with the riboseq dataframe\n",
    "\n",
    "# Explode the dataframe to have one row per position\n",
    "\n",
    "\n",
    "# Make the positions column the index\n",
    "\n",
    "\n",
    "# Remove columns we don't need anymore (start, end)\n",
    "\n",
    "\n",
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently, we want to append dataframes together to combine multiple datasets.\n",
    "\n",
    "Concatenate two or more dataframes:\n",
    "- `pd.concat([df1, df2, df3], axis=0)` to stack the dataframes one on top of the other\n",
    "- `pd.concat([df1, df2, df3], axis=1)` to glue the dataframes side by side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the riboseq dataframes into a single dataframe\n",
    "# so that we can merge it with the annotations dataframe\n",
    "\n",
    "# Concatenate all three riboseq dataframes\n",
    "riboseq = \n",
    "\n",
    "riboseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And perhaps the most useful way to combine dataframes is merging. We can merge any two dataframes that share one or more column names.\n",
    "\n",
    "Merge two dataframes:\n",
    "- `pd.merge(df1, df2, on='col', how='left')` to merge on one column and keep all values from df1 in that column\n",
    "- `pd.merge(df1, df2, on='col', how='right')` to merge on one column and keep all values from df2 in that column\n",
    "- `pd.merge(df1, df2, on='col', how='inner')` to merge on one column and keep all values shared by both dfs\n",
    "- `pd.merge(df1, df2, on='col', how='outer')` to merge on one column and keep all values in either df\n",
    "- `pd.merge(df1, df2, on=['col1','col2']')` to merge on multiple columns\n",
    "\n",
    "And don't forget we can make sure our datatypes are what we expect after merging:\n",
    "- `df.astype({'col1':'int', 'col2':'float})`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the annotations and riboseq dataframes into a single dataframe\n",
    "\n",
    "# Merge the two dataframes on the position columns, keep all positions in the annotations dataframe\n",
    "merged_data = \n",
    "\n",
    "# Make sure the data types are what we want for each column (reads: float, timepoint: int)\n",
    "\n",
    "\n",
    "# Reset the index so position is a column we can access\n",
    "\n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate new columns from transformations of existing columns. Often this involves grouping the data by some feature and calculating a value of each group. Or it may be a row-by-row calculation.\n",
    "\n",
    "Calculate a new value per group:\n",
    "- `df.groupby(['col1','col2'])['col3'].transform('count')` to create a new column with the number of elements in each group\n",
    "- `df.groupby(['col1','col2'])['col3'].transform('mean')` to create a new column with the mean of each group\n",
    "\n",
    "Clauclate a new value per row:\n",
    "- `df['new_col'] = np.log(df['col1'])` to create a new column with the log of an existing column\n",
    "- `df['new_col'] = df['col1'] / df['col2']` to create a new column normalizing one column by another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the reads by the mean reads per gene\n",
    "\n",
    "# Add a column with the mean reads per gene for each timepoint\n",
    "merged_data['mean_reads'] = \n",
    "\n",
    "# Add a column with the reads normalized by mean reads per transcript\n",
    "merged_data['norm_reads'] = \n",
    "\n",
    "# Add a column with the log of normalized reads (plus a pseudocount of 1)\n",
    "merged_data['log_norm_reads'] = \n",
    "\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn styles\n",
    "\n",
    "One of the best features of seaborn is that it defaults to making beautiful plots! But still gives you the ability to customize all the visuals.\n",
    "\n",
    "Set the [color palette](https://matplotlib.org/stable/tutorials/colors/color1s.html), for example from these [creatively named colors](https://xkcd.com/color/rgb/):\n",
    "- `sns.set_palette(sns.color_palette(colors))` to set a custom color palette\n",
    "\n",
    "Set the [plot style](http://seaborn.pydata.org/tutorial/aesthetics.html):\n",
    "- `sns.set_style('darkgrid')`\n",
    "- `sns.set_style('whitegrid')`\n",
    "- `sns.set_style('dark')`\n",
    "- `sns.set_style('white')`\n",
    "- `sns.set_style('ticks')`\n",
    "\n",
    "Set the [context](http://seaborn.pydata.org/tutorial/aesthetics.html):\n",
    "- `sns.set_context('notebook', font_scale=1.05)` to rescale the fonts for jupyter notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = ['#2E659D', '#CA4B4C', '#F0BF1A']\n",
    "colors = ['xkcd:pastel red', 'xkcd:squash',  'xkcd:sun yellow', 'xkcd:off green', 'xkcd:dull teal', \n",
    "          'xkcd:faded blue', 'xkcd:denim blue', 'xkcd:light eggplant', 'xkcd:ugly pink', 'xkcd:grey']\n",
    "\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "sns.set_style('ticks')\n",
    "sns.set_context('notebook', font_scale=1.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single plots\n",
    "\n",
    "As discussed last week, we can make a seaborn plot from a dataframe pretty easily. Here's an overview and some example plot types that are especially useful.\n",
    "\n",
    "Create a matplotlib figure:\n",
    "- `fig1, ax1 = plt.subplots(figsize=(10,3))` to create a matplotlib figure and axes object of the given size\n",
    "\n",
    "Create a [seaborn plot](https://seaborn.pydata.org/examples/index.html):\n",
    "- `sns.scatterplot(data=df, x='col1', y='col2', hue='col3', ax=ax1)` to make a scatter plot\n",
    "- `sns.lineplot(data=df, x='col1', y='col2', hue='col3', ax=ax1)` to make a line plot\n",
    "- `sns.histplot(data=df, x='col1', hue='col3', ax=ax1)` to make a histogram\n",
    "- `sns.stripplot(data=df, x='col1', y='col2', hue='col3', ax=ax1)` to make a categorial scatter plot\n",
    "- `sns.boxplot(data=df, x='col1', y='col2', hue='col3', ax=ax1)` to make a categorical box plot\n",
    "- `sns.barplot(data=df, x='col1', y='col2', hue='col3', ax=ax1)` to make a categorical bar plot\n",
    "\n",
    "Customize axis limits:\n",
    "- `ax1.set_xlim([0,10])` to force the x-axis limits to be 0 to 10\n",
    "- `ax1.set_xylim([0,10])` to force the y-axis limits to be 0 to 10\n",
    "\n",
    "Label the axes and plot:\n",
    "- `ax1.set_xlabel('x')` to label the x-axis\n",
    "- `ax1.set_ylabel('y')` to label the y-axis\n",
    "- `ax1.set_title('plot', fontweight='bold', fontsize=14)` to label the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the log normalized reads over each position of the gene ORF7b\n",
    "\n",
    "# Isolate the subset of data for one gene\n",
    "plot_data = merged_data[merged_data['gene']=='ORF7b']\n",
    "\n",
    "# Plot using sns.lineplot\n",
    "fig1, ax1 = \n",
    "\n",
    "\n",
    "# Update the limits\n",
    "pos_min = # Min position value\n",
    "pos_max = # Max position value\n",
    "\n",
    "\n",
    "# Upadate the labels\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a summary of the read counts per gene\n",
    "\n",
    "# Remove the longest gene so that we can plot the rest in a reasonable amount of time\n",
    "sample_data = merged_data[merged_data['gene']!='ORF1ab']\n",
    "\n",
    "# Plot a boxplot of the reads at each timepoint for each gene\n",
    "fig2, ax2 = \n",
    "\n",
    "# Update the limits\n",
    "\n",
    "\n",
    "# Upadate the labels\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipanel plots\n",
    "\n",
    "Another strength of seaborn is making multipanel plots from a dataframe.\n",
    "\n",
    "Create a [seaborn faceted plot](https://seaborn.pydata.org/examples/index.html):\n",
    "- `sns.relplot(data=df, x='col1', y='col2', hue='col3', col='col4', col_wrap=5, kind='scatter')` to make a multipanel scatter plot\n",
    "- `sns.relplot(data=df, x='col1', y='col2', hue='col3', col='col4', col_wrap=5, kind='line')` to make a multipanel line plot\n",
    "- `sns.displot(data=df, x='col1', y='col2', hue='col3', col='col4', col_wrap=5, kind='hist')` to make a multipanel histogram\n",
    "- `sns.catplot(data=df, x='col1', y='col2', hue='col3', col='col4', col_wrap=5, kind='strip')` to make a multipanel categorical scatter plot\n",
    "- `sns.catplot(data=df, x='col1', y='col2', hue='col3', col='col4', col_wrap=5, kind='box')` to make a multipanel categorical box plot\n",
    "- `sns.catplot(data=df, x='col1', y='col2', hue='col3', col='col4', col_wrap=5, kind='bar')` to make a multipanel categorical bar plot\n",
    "\n",
    "Label the axes and plot:\n",
    "- `g1.fig.set_axis_labels('x', 'y')` to label the x-axi and y-axis\n",
    "- `g1.fig.subplots_adjust(top=0.9)` to add space at the top for a super-title\n",
    "- `g1.fig.suptitle('plot', fontweight='bold', fontsize=14)` to label the plot with a a super-title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean reads over time for each gene\n",
    "\n",
    "# Plot a lineplot of the mean reads at each timepoint for each gene\n",
    "g3 = \n",
    "\n",
    "# Upadate the labels\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tada!\n",
    "\n",
    "Now you're Pandas and Seaborn pro. Just for a fun (and totally random) bonus, here's how you can make your own [xkcd style plots](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.xkcd.html) in python!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word of caution\n",
    "\n",
    "Pandas is an extremely powerful data science tool, but it is also extremely memory-hungry. As a rule of thumb, pandas requires 5x to 10x as much RAM as the size of the dataset you're loading.\n",
    "\n",
    "![Pandas](https://uploads-ssl.webflow.com/5b6106c192c3f985a0cb3273/5cde13a9dd9cda26144a59fc_Panda.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
